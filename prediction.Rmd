---
title: "Prediction Assignment"
author: "Lucas Antelo"
date: "31 Mai 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Executive Summary
The data set.

## Getting The Data

The data set for this assignment consists of the weight lifting exercise dataset provided by Velloso, E and co (1). It consists of 5 different groups doing the weight lifting exercises under 5 different conditions. Group A under correct conditions and the other four with mistakes of different degree all under the surveillance of an experienced observer.

| A | exactly according to the specification |
| B | throwing the elbows to the front |
| C | lifting the dumbbell only halfway |
| D | lowering the dumbbell only halfway |
| E | throwing the hips to the front |

We download the data and read them as training and validation set from the .csv file. As the training set has many observations, we can construct from the training set 2 subsets for training and testing purposes and finally to blend and construct an ensemble learning model.

```{r getting, cache=TRUE, results='hide'}
urlTrainingData <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
urlTestingData <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
date_downloaded <- date()
download.file(urlTrainingData, destfile = "training.csv")
download.file(urlTestingData, destfile = "testing.csv")
training <- read.csv("training.csv",strip.white = TRUE, na.strings = c("#DIV/0!", "NA"))
dim(training)
validation <- read.csv("testing.csv", strip.white=TRUE, na.strings = c("#DIV/0!", "NA"))
rm("urlTrainingData", "urlTestingData") #remove variables to free memory space
```

## Cleaning The Data

The data set contains many variables and observations which will be reduced to the asked data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants as well as the outcome classe. Furthermore I especially took further variables for the belt, forearm and dumbbell, as the majority of the movement will be in the forearm, the hip in class E and the dumbbell. In this way we have 29 variables and the outcome classe.

```{r cleaning, echo=TRUE, results='hide'}
summary(training)

#looked at the dataset and wrote down all the variables that are necessary for this assignment. 
asked <- c("classe", "roll_belt","pitch_belt", "yaw_belt" ,"accel_belt_x","accel_belt_y", "accel_belt_z", "magnet_belt_x", "magnet_belt_y", "magnet_belt_z", "accel_arm_x", "accel_arm_y", "accel_arm_z", "roll_forearm", "pitch_forearm", "yaw_forearm" ,"accel_forearm_x", "accel_forearm_y", "accel_forearm_z", "magnet_forearm_x", "magnet_forearm_y","magnet_forearm_z", "roll_dumbbell", "pitch_dumbbell" ,"accel_dumbbell_x", "accel_dumbbell_y", "accel_dumbbell_z", "magnet_dumbbell_x", "magnet_dumbbell_y", "magnet_dumbbell_z")

training <- training[,asked]

sum(!complete.cases(training)) #0, thus only complete cases
dim(training) #[1] 19622    30
```
Now we have a much smaller number of variables (from 160 to 30) which will be used to construct our prediction model. First I will construct three different standalone models:
1. Random Forest model
2. Linear Discriminant model
3. Boosting model

The cross validation will be done with the subset trainSet from training with confusionMatrix, from which I get the accuracy values for each model. Then I will construct a model as a standalone or in combination of models.


## Prediction Model

From the original training set I will construct two subsets with the help of the caret package, One subset will be used for training purposes. The second for testing.

```{r subsetsForTraining, results='hide', cache = TRUE, warning=FALSE}
set.seed(12121)#in order to be reproducible
library(caret)
library(randomForest)

inTrain <- createDataPartition(y = training$classe, p = 0.7, list = FALSE)
trainSet <- training[inTrain,]
testSet <- training[-inTrain,]
```


###1. Random Forest Model
```{r randomForest, cache=TRUE, warning=FALSE}
setting <- trainControl(allowParallel=T, method="cv", number=4)#to work faster, but still very slow :-(

modRF <- train(classe ~ ., data = trainSet, method = "rf", trainControl=setting)

predictionsRF <- predict(modRF, newdata = testSet)

confusionMatrix(predictions, testSet$classe) #Accuracy 0.9905 [0.9877, 0.9928]
table(predictions, testSet$classe)
varImp(modRF)
```
This model provides a very good accuracy value, which can almost be used alone.


###2. Linear Discriminant Model
```{r linearDiscriminant, cache=TRUE, warning=FALSE}
library(MASS)
modLDA <- train(classe ~ ., data = trainSet, method = "lda")

predictionsLDA <- predict(modLDA, newdata = testSet)

confusionMatrix(predictions, testSet$classe) #Accuracy 0.6545 [0.6422, 0.6667]
table(predictions, testSet$classe)
```
The accuracy for this model is much lower compared to the random forest model, such that it could only be helpful in combination with the first model.


###3. Boosting Model
```{r boosting, cache = TRUE, warning = FALSE}
library(plyr)
library(survival)
library(splines)
library(parallel)
modB <- train(classe ~ ., data = trainSet, method = "gbm", verbose = FALSE)

predictionsB <- predict(modB, newdata = testSet)

confusionMatrix(predictions, testSet$classe)
table(predictions, testSet$classe)
```
With an accuracy of 0.9568 and a 95% confidence interval of (0.9513, 0.9619) it is pretty good, but not as good as random forest. 


##Validation

```{r validation, cache = TRUE, warning=FALSE}
predictionsV <- predict(modRF, validation)#doesn't work appropriately
```



(1) Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.
Read more: http://groupware.les.inf.puc-rio.br/har#ixzz4AKmYoNy4
