---
title: "Qualitative Activity Prediction Model"
author: "Lucas Antelo"
date: "31 Mai 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Executive Summary
In this project, we use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants, that were asked to perform barbell lifts correctly and incorrectly in 5 different ways. The descriptioin of the experiment can be found at 'http://groupware.les.inf.puc-rio.br/har' under the section 'Weight Lifting Exercise Dataset'. The data set was provided by Velloso, E and co (1).

The training dataset was split into a training, test and validation subset. We trained four different models with the training subset and tested them separately with the test subset. Following the results of the confusionMatrix method we chose the random forest model as our final model showing an accuracy of 0.9879 and a 95% confidence interval of (0.984, 0.991). This final model was validated with our validation subset showing a drop of accuracy of only 0.0017 or 0.17%. Thus its accuracy remained very high with 0.9862 and a 95% confidence interval of (0.9829, 0.9891).


## Getting The Data
6 participants were asked to perform barbell lifts under 5 different conditions, which are classified as groups from A to E, all under the surveillance of an experienced observer.

 A : exactly according to the specification (correctly)  
 B : throwing the elbows to the front (incorrectly)  
 C : lifting the dumbbell only halfway (incorrectly)  
 D : lowering the dumbbell only halfway (incorrectly)  
 E : throwing the hips to the front (incorrectly)  

Two data sets are downloaded from a specific source consisting in a training set and quiz set for the Practical Machine Learning Quiz at coursera.
```{r getting, cache=TRUE, results='hide'}
urlTrainingData <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
urlTestingData <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
date_downloaded <- date()
download.file(urlTrainingData, destfile = "training.csv")
download.file(urlTestingData, destfile = "testing.csv")
training <- read.csv("training.csv",strip.white = TRUE, na.strings = c("#DIV/0!", "NA"))
dim(training) #[1] 19622 160
quizSet <- read.csv("testing.csv", strip.white=TRUE, na.strings = c("#DIV/0!", "NA")) #Prediction Quiz
```

## Cleaning The Data
The number of variables in the training set will be reduced, such that only variables from accelerometers on the belt, forearm, arm, and dumbell are retained and used to build our prediction models. Morevover further variables are retained, that could be significant in predicting the correct outcome, named as 'classe' in the data set representing one of the five groups (A - E). Finally, from 160 variables, 29 predictors and 1 outcome are used to build our models.

```{r cleaning, echo=TRUE, results='hide'}
summary(training)

#looked at the dataset and wrote down all the variables that are necessary for this assignment. 
asked <- c("classe", "roll_belt","pitch_belt", "yaw_belt" ,"accel_belt_x","accel_belt_y", "accel_belt_z", "magnet_belt_x", "magnet_belt_y", "magnet_belt_z", "accel_arm_x", "accel_arm_y", "accel_arm_z", "roll_forearm", "pitch_forearm", "yaw_forearm" ,"accel_forearm_x", "accel_forearm_y", "accel_forearm_z", "magnet_forearm_x", "magnet_forearm_y","magnet_forearm_z", "roll_dumbbell", "pitch_dumbbell" ,"accel_dumbbell_x", "accel_dumbbell_y", "accel_dumbbell_z", "magnet_dumbbell_x", "magnet_dumbbell_y", "magnet_dumbbell_z")

training <- training[,asked]

sum(!complete.cases(training)) #0, thus only complete cases
dim(training) #[1] 19622    30
```

With the cleaned data set we will build four different models.

1. Random Forest model  
2. Linear Discriminant model  
3. Boosting model  
4. Predictive Tree model  

The construction of these models will be done with the caret package and the appropriate methods. After building the first four models, the accuracy and results will be measured with the method confusionMatrix() and its results will decide our final model. The final model will be tested using a validation subset. 


## Prediction Model
The number of observations in the original training data set allows us to construct a training subset, a test subset and a validation subset. The training subset will be used to train the first four models, which will be tested with the test subset. Only the final model will be validated. As the in sample error will always be lower than the out sample error, we expected the models to perform worse on new sample sets. The expected drop in accuracy (1 - out sample error) will be mentioned for each model by personal guesses. An accuracy of 20% shows that the model would be as good as guessing by chance.

```{r subsetsForTraining, results='hide',cache = TRUE, message=FALSE, warning=FALSE}
set.seed(12121)#in order to be reproducible for others

library(caret)
library(randomForest)

inBuild <- createDataPartition(y = training$classe, p = 0.7, list = FALSE)

validation <- training[-inBuild,]
buildData <- training[inBuild,]

inTrain <- createDataPartition(y = buildData$classe, p = 0.7, list = FALSE)

trainSet <- buildData[inTrain,]
testSet <- buildData[-inTrain,]
```


###1. Random Forest Model
This model provides a very good accuracy for the test subset, but it takes an incredible amount of time. Unfortunately due to overfitting, the out of sample error could be quite high, such that we could expect a drop in accuracy at around 90% or lower. The method varImp shows us the 20 most important variables for its prediction.
```{r randomForest, cache=TRUE, warning=FALSE}
setting <- trainControl(allowParallel=T, method="cv", number=4) #to work faster, but still very slow :-(

modRF <- train(classe ~ ., data = trainSet, method = "rf", trainControl=setting)

predictionsRF <- predict(modRF, newdata = testSet)

confusionMatrix(predictionsRF, testSet$classe)

varImp(modRF)
```


###2. Linear Discriminant Model
This model provides a much lower accuracy compared to the random forest model and could only be helpful in combination with our first model. The expected out of sample error with a new sample could be around 40% and if unlucky above 50%. 
```{r linearDiscriminant, cache=TRUE, warning=FALSE}
library(MASS)
modLDA <- train(classe ~ ., data = trainSet, method = "lda")

predictionsLDA <- predict(modLDA, newdata = testSet)

confusionMatrix(predictionsLDA, testSet$classe) #Accuracy 0.6545 [0.6422, 0.6667]
```


###3. Boosting Model
This models provides very good results and a very high accuracy. By combining it with our first model, we could improve the accuracy for new samples. The expected accuracy on new samples will be lower, thus giving a higher out of sample error, but we can't estimate by how much.
```{r boosting, cache = TRUE, message=FALSE, warning = FALSE}
library(plyr)
library(survival)
library(splines)
library(parallel)
library(ggplot2)
library(gbm)

#takes a lot of time
modB <- train(classe ~ ., data = trainSet, method = "gbm", verbose = FALSE)

predictionsB <- predict(modB, newdata = testSet)

confusionMatrix(predictionsB, testSet$classe)
```


###4. Predictive Tree Model
This model has the worst performance so far with an accuracy of around 50%. The out of sample error will be higher, but we can't estimate by how much.
```{r trees, cache = TRUE, message=FALSE, warning=FALSE}
library(rattle)
modT <- train(classe ~ ., data = trainSet, method = "rpart")

predictionsT <- predict(modT, testSet)

confusionMatrix(predictionsT, testSet$classe)

fancyRpartPlot(modT$finalModel)
```
 
###5. Final Model
Our first model showed such a high accuracy that it will be used as a standalone model for our validation set showing an accuracy of 0.9862 with a 95% confidence interval of (0.9829, 0.9891). The expected drop of accuracy due to the out of sample error was much smaller than expected, which increased only by 0.0017 or 0.17%.
```{r finalModel, cache = TRUE, message=FALSE, warning=FALSE}
predictions <- predict(modRF, validation)

confusionMatrix(predictions, validation$classe)
```

##Course Project Prediction Quiz

```{r validation, cache = TRUE, warning=FALSE}
predictionsQuiz <- predict(modRF, quizSet)
quizDF <- data.frame(predictions = predictionsQuiz, quizSet) 
```



(1) Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.
Read more: http://groupware.les.inf.puc-rio.br/har#ixzz4AKmYoNy4
